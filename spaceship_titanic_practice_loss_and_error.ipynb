{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn   # neural network modules\n",
    "import torch.optim as optim   # optimization algorithms\n",
    "import torch.nn.functional as F   # functions without parameters like activation functions\n",
    "from torch.utils.data import TensorDataset, DataLoader   # dataset management, create batches\n",
    "import torchvision.datasets as datasets   # standard datasets on pytorch\n",
    "import torchvision.transforms as transforms   #transform datasets\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train dataset shape is (8693, 14)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_csv(\"train.csv\")\n",
    "\n",
    "print(\"Full train dataset shape is {}\".format(train_dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8514.000000</td>\n",
       "      <td>8512.000000</td>\n",
       "      <td>8510.000000</td>\n",
       "      <td>8485.000000</td>\n",
       "      <td>8510.000000</td>\n",
       "      <td>8505.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.827930</td>\n",
       "      <td>224.687617</td>\n",
       "      <td>458.077203</td>\n",
       "      <td>173.729169</td>\n",
       "      <td>311.138778</td>\n",
       "      <td>304.854791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.489021</td>\n",
       "      <td>666.717663</td>\n",
       "      <td>1611.489240</td>\n",
       "      <td>604.696458</td>\n",
       "      <td>1136.705535</td>\n",
       "      <td>1145.717189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>14327.000000</td>\n",
       "      <td>29813.000000</td>\n",
       "      <td>23492.000000</td>\n",
       "      <td>22408.000000</td>\n",
       "      <td>24133.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age   RoomService     FoodCourt  ShoppingMall           Spa  \\\n",
       "count  8514.000000   8512.000000   8510.000000   8485.000000   8510.000000   \n",
       "mean     28.827930    224.687617    458.077203    173.729169    311.138778   \n",
       "std      14.489021    666.717663   1611.489240    604.696458   1136.705535   \n",
       "min       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      19.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%      27.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%      38.000000     47.000000     76.000000     27.000000     59.000000   \n",
       "max      79.000000  14327.000000  29813.000000  23492.000000  22408.000000   \n",
       "\n",
       "             VRDeck  \n",
       "count   8505.000000  \n",
       "mean     304.854791  \n",
       "std     1145.717189  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%       46.000000  \n",
       "max    24133.000000  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine dataset\n",
    "train_dataset.head()\n",
    "train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop id and name columns as they are not important\n",
    "train_dataset = train_dataset.drop(['PassengerId', 'Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace nan values with 0\n",
    "train_dataset.isnull().sum().sort_values(ascending=False)\n",
    "train_dataset[['VIP', 'CryoSleep', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck','HomePlanet','Destination']] = train_dataset[['VIP', 'CryoSleep', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck','HomePlanet','Destination']].fillna(value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace strings with numbers\n",
    "train_dataset['HomePlanet'].unique()\n",
    "train_dataset['HomePlanet'] = train_dataset['HomePlanet'].replace({'Earth':1, 'Europa':2, 'Mars':3})\n",
    "\n",
    "train_dataset['Destination'].unique()\n",
    "train_dataset['Destination'] = train_dataset['Destination'].replace({'TRAPPIST-1e':1, '55 Cancri e':2, 'PSO J318.5-22':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace booleans with int\n",
    "target = 'Transported'\n",
    "train_dataset[target] = train_dataset[target].astype(int)\n",
    "train_dataset['VIP'] = train_dataset['VIP'].astype(int)\n",
    "train_dataset['CryoSleep'] = train_dataset['CryoSleep'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace cabin number with 3 different columns\n",
    "train_dataset[['Deck', 'Cabin_num', 'Side']] = train_dataset['Cabin'].str.split(\"/\", expand=True)\n",
    "train_dataset['Deck'].unique()\n",
    "train_dataset['Cabin_num'].unique()\n",
    "train_dataset['Cabin_num'].isnull().values.any()\n",
    "train_dataset['Side'].unique()\n",
    "\n",
    "train_dataset[['Deck', 'Cabin_num', 'Side']] = train_dataset[['Deck', 'Cabin_num', 'Side']].fillna(value=0)\n",
    "train_dataset['Deck'] = train_dataset['Deck'].replace({'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7, 'T':8})\n",
    "train_dataset['Side'] = train_dataset['Side'].replace({'P':1, 'S':2})\n",
    "train_dataset['Cabin_num'] = train_dataset['Cabin_num'].astype(int)\n",
    "train_dataset = train_dataset.drop('Cabin', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Cabin_num</th>\n",
       "      <th>Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomePlanet  CryoSleep  Destination   Age  VIP  RoomService  FoodCourt  \\\n",
       "0           2          0            1  39.0    0          0.0        0.0   \n",
       "1           1          0            1  24.0    0        109.0        9.0   \n",
       "2           2          0            1  58.0    1         43.0     3576.0   \n",
       "3           2          0            1  33.0    0          0.0     1283.0   \n",
       "4           1          0            1  16.0    0        303.0       70.0   \n",
       "\n",
       "   ShoppingMall     Spa  VRDeck  Transported  Deck  Cabin_num  Side  \n",
       "0           0.0     0.0     0.0            0     2          0     1  \n",
       "1          25.0   549.0    44.0            1     6          0     2  \n",
       "2           0.0  6715.0    49.0            0     1          0     2  \n",
       "3         371.0  3329.0   193.0            0     1          0     2  \n",
       "4         151.0   565.0     2.0            1     6          1     2  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and val split\n",
    "train_df = train_dataset.sample(frac=0.8, random_state=123)\n",
    "val_df = train_dataset.drop(train_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to tensors\n",
    "train_x = torch.tensor(train_df.drop(\"Transported\", axis=1).values, dtype=torch.float32)\n",
    "train_y = torch.tensor(train_df[\"Transported\"].values, dtype=torch.float32)\n",
    "val_x = torch.tensor(val_df.drop(\"Transported\", axis=1).values, dtype=torch.float32)\n",
    "val_y = torch.tensor(val_df[\"Transported\"].values, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "val_dataset = TensorDataset(val_x, val_y)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "input_size = train_x.shape[1]\n",
    "num_classes = 1 #if probability greater than 0.5, then True, if less then False\n",
    "learning_rate = 0.001  \n",
    "num_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 100)\n",
    "        self.fc2 = nn.Linear(100,50)\n",
    "        self.fc3 = nn.Linear(50, num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = NN(input_size=input_size, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of iter(training_loader) so that we can track the batch index and do some intra-epoch reporting\n",
    "    for index, data in enumerate(train_loader):\n",
    "\n",
    "        # Every data instance is an input + label pair\n",
    "        batch_x, batch_y = data\n",
    "        \n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(batch_x)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = criterion(outputs.squeeze(), batch_y)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item() #retrieves the scalar value of the loss function for the current batch\n",
    "        if index % 10 == 9: #reports on loss every 10 batches\n",
    "            last_loss = running_loss / 10 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(index + 1, last_loss))\n",
    "            tb_x = epoch_index * len(train_loader) + index + 1  #variable is used to set the x-axis value for the scalar summary in TensorBoard, based on the current epoch and batch index\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0\n",
    "\n",
    "    return last_loss #last calculated batch loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 10 loss: nan\n",
      "  batch 20 loss: nan\n",
      "  batch 30 loss: nan\n",
      "  batch 40 loss: nan\n",
      "  batch 50 loss: nan\n",
      "  batch 60 loss: nan\n",
      "  batch 70 loss: nan\n",
      "  batch 80 loss: nan\n",
      "  batch 90 loss: nan\n",
      "  batch 100 loss: nan\n",
      "LOSS train nan valid nan\n",
      "EPOCH 2:\n",
      "  batch 10 loss: nan\n",
      "  batch 20 loss: nan\n",
      "  batch 30 loss: nan\n",
      "  batch 40 loss: nan\n",
      "  batch 50 loss: nan\n",
      "  batch 60 loss: nan\n",
      "  batch 70 loss: nan\n",
      "  batch 80 loss: nan\n",
      "  batch 90 loss: nan\n",
      "  batch 100 loss: nan\n",
      "LOSS train nan valid nan\n",
      "EPOCH 3:\n",
      "  batch 10 loss: nan\n",
      "  batch 20 loss: nan\n",
      "  batch 30 loss: nan\n",
      "  batch 40 loss: nan\n",
      "  batch 50 loss: nan\n",
      "  batch 60 loss: nan\n",
      "  batch 70 loss: nan\n",
      "  batch 80 loss: nan\n",
      "  batch 90 loss: nan\n",
      "  batch 100 loss: nan\n",
      "LOSS train nan valid nan\n",
      "EPOCH 4:\n",
      "  batch 10 loss: nan\n",
      "  batch 20 loss: nan\n",
      "  batch 30 loss: nan\n",
      "  batch 40 loss: nan\n",
      "  batch 50 loss: nan\n",
      "  batch 60 loss: nan\n",
      "  batch 70 loss: nan\n",
      "  batch 80 loss: nan\n",
      "  batch 90 loss: nan\n",
      "  batch 100 loss: nan\n",
      "LOSS train nan valid nan\n",
      "EPOCH 5:\n",
      "  batch 10 loss: nan\n",
      "  batch 20 loss: nan\n",
      "  batch 30 loss: nan\n",
      "  batch 40 loss: nan\n",
      "  batch 50 loss: nan\n",
      "  batch 60 loss: nan\n",
      "  batch 70 loss: nan\n",
      "  batch 80 loss: nan\n",
      "  batch 90 loss: nan\n",
      "  batch 100 loss: nan\n",
      "LOSS train nan valid nan\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/spaceship_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "    # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    for index, vdata in enumerate(val_loader):\n",
    "        vbatch_x, vbatch_y = vdata\n",
    "        voutputs = model(vbatch_x)\n",
    "        vloss = criterion(voutputs.squeeze(), vbatch_y)\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (index + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader,model): \n",
    "    if loader == train_loader: \n",
    "        print(\"checking accuracy on training data\")\n",
    "    else:\n",
    "        print(\"checking accuracy on test data\")\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() \n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for x,y in loader:\n",
    "            x= x.to(device=device)\n",
    "            y= y.to(device=device)\n",
    "            \n",
    "            outputs = model(x)\n",
    "            probs = torch.sigmoid(outputs).squeeze() #maps any input value to a probability value between 0 and 1\n",
    "            preds = (probs > 0.5).to(torch.float32) #applies a threshold of 0.5 to the predicted probabilities, then converts boolean to float\n",
    "            \n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += x.shape[0]\n",
    "            \n",
    "        print(f'{num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')   #2dp\n",
    "        \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking accuracy on training data\n",
      "3447 / 6954 with accuracy 49.57\n",
      "checking accuracy on test data\n",
      "868 / 1739 with accuracy 49.91\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(train_loader,model)\n",
    "check_accuracy(val_loader,model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
